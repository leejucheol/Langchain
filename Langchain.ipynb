{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1FqhkSOQ55n"
      },
      "source": [
        "\n",
        "LangChain과 ChromaDB를 이용한 간단한 검색 시스템 구축(LLM 없음)\n",
        "\n",
        "목적:\n",
        "\n",
        "학생들은 LangChain과 ChromaDB를 활용해 문서 검색 시스템을 구축하고, 한국어 데이터세트에서 가장 관련성이 높은 문서나 텍스트 조각을 반환하여 질의에 답합니다.\n",
        "\n",
        "Instruction\n",
        "\n",
        "1. 환경 설정\n",
        "\n",
        "필요한 라이브러리를 설치하세요:\n",
        "랭체인\n",
        "크로마디비\n",
        "개발에는 Python IDE나 Jupyter Notebook을 사용하세요.\n",
        "\n",
        "2. 소규모 데이터 세트 준비\n",
        "\n",
        "100-200개 항목으로 한국어 데이터 세트를 만들거나 다운로드하세요. 예:\n",
        "한국 속담과 그 의미.\n",
        "간단한 설명과 함께 소개된 한국의 유명한 역사적 사건 목록입니다.\n",
        "인기 있는 한국 요리와 재료\n",
        "데이터 세트를 제목과 설명이라는 두 개의 열이 있는 CSV 파일로 포맷합니다.\n",
        "\n",
        "3. ChromaDB에 데이터 로드\n",
        "\n",
        "데이터 세트를 사전 처리합니다.\n",
        "LangChain 호환 임베딩 모델을 사용하여 설명 열을 벡터 임베딩으로 변환합니다.\n",
        "ChromaDB 데이터베이스에 임베딩을 저장합니다.\n",
        "\n",
        "4. 검색 파이프라인 구현\n",
        "\n",
        "다음과 같은 쿼리 시스템을 만듭니다.\n",
        "The user inputs a query in Korean (e.g., “김치의 재료는 무엇인가요?”).\n",
        "시스템은 쿼리와의 유사성을 기반으로 ChromaDB 데이터베이스에서 가장 관련성 있는 설명을 검색합니다.\n",
        "\n",
        "5. 검색 결과 평가\n",
        "\n",
        "20~30개의 쿼리로 시스템을 테스트하고 검색된 결과의 정확성을 수동으로 확인합니다.\n",
        "예시 쿼리:\n",
        "“다음 속담의 의미를 설명하시오: 하늘이 무너져도 솟아날 구멍이 있다.\"\n",
        "\n",
        "6. 성과물\n",
        "\n",
        "검색 시스템을 구현하는 Python 스크립트(retrieval_pipeline.py)(충분한 주석이 포함되어야 함)\n",
        "다음을 포함한 MS Word 형식의 보고서:\n",
        "데이터 세트에 대한 설명.\n",
        "검색 과정에 대한 설명.\n",
        "테스트 쿼리의 결과(입력 및 검색된 설명).\n",
        "직면한 과제와 실행된 해결책.\n",
        "\n",
        "\n",
        "**과제를 시작하기 전, 과제에 필요한 모듈을 다운로드 합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Fay-28sAKcIY"
      },
      "outputs": [],
      "source": [
        "!pip install langchain chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qku_ST8MSC6Q"
      },
      "source": [
        "## **1) 필요한 라이브러리 설치**\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "LangChain과 ChromaDB를 설치합니다.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWgQLW1LR-av"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import langchain\n",
        "import chromadb\n",
        "import os\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCPnzMi8S64C"
      },
      "source": [
        "## **2) 소규모 데이터 세트 준비**\n",
        "\n",
        "---\n",
        "\n",
        "200개 항목으로 구성된 한국어 데이터 세트를 CSV 파일로 포맷한다.\n",
        "속담과 관용구로 데이터 세트를 제목과 설명 두 개의 열로 구성되어있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NmMAPHQfS7Ea"
      },
      "outputs": [],
      "source": [
        "# CSV 파일 로드 및 문서 분리\n",
        "# CSVLoader를 사용하여 지정된 파일 경로에서 데이터를 로드합니다.\n",
        "# 'cp949' 인코딩을 사용하여 한글 데이터가 깨지지 않도록 처리합니다.\n",
        "# 로드된 데이터를 documents 변수에 저장합니다.\n",
        "csv_loader = CSVLoader(file_path='/content/nanolabdataset.csv', encoding='cp949')\n",
        "documents = csv_loader.load()\n",
        "\n",
        "# 텍스트 분리기 초기화\n",
        "# CharacterTextSplitter는 텍스트를 일정 크기로 분리하는 도구입니다.\n",
        "# 'chunk_size=100'은 각 텍스트 조각의 최대 길이를 100자로 설정합니다.\n",
        "# 'chunk_overlap=0'은 텍스트 조각 간 중첩이 없도록 설정합니다.\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "\n",
        "# 문서 분리 실행\n",
        "# 로드된 문서 데이터를 100자 크기로 분리하여 검색에 적합한 형식으로 변환합니다.\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDpiIJE0TXhG"
      },
      "source": [
        "## **3) ChromaDB에 데이터를 로드합니다**\n",
        "\n",
        "---\n",
        "\n",
        "원본 데이터를 검색 시스템에 적합하도록 전처리한다.\n",
        "\n",
        "데이터는 CharacterTextSplitter를 통해 100자로 나눠져 있다.\n",
        "LangChain 호환 임베딩 모델을 사용하여 설명 열을 벡터 임베딩으로 변환한다.\n",
        "\n",
        "OpenAIEmbeddings는 LangChain에서 제공하는 호환 벡터 임베딩 모델이다. 각 텍스트를 고차원 벡터로 변환한다.\n",
        "\n",
        "```\n",
        "texts\n",
        "OpenAIEmbeddings\n",
        "Chroma.from_documents\n",
        "```\n",
        "ChromaDB에 데이터 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fBzOmxMbTXws"
      },
      "outputs": [],
      "source": [
        "# 벡터 임베딩 및 ChromaDB 저장\n",
        "# OpenAIEmbeddings는 LangChain에서 제공하는 임베딩 모델입니다.\n",
        "# 입력된 텍스트 데이터를 고차원 벡터로 변환하여 의미론적 검색에 사용됩니다.\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Chroma.from_documents()는 텍스트 데이터를 벡터로 변환한 후 ChromaDB 데이터베이스에 저장합니다.\n",
        "# 'texts'는 사전에 처리된 텍스트 조각이고, 'embeddings'는 이를 벡터화하는 데 사용됩니다.\n",
        "# 결과로 반환된 'vector_store'는 벡터 데이터베이스로, 검색에 사용됩니다.\n",
        "vector_store = Chroma.from_documents(texts, embeddings)\n",
        "# 검색기 생성\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})  # 가장 유사한 2개 문서 검색\n",
        "\n",
        "system_template=\"\"\"Use the following pieces of context to answer the users question shortly.\n",
        "Given the following summaries of a long document and a question, create a final answer with references (\"SOURCES\"), use \"SOURCES\" in capital letters regardless of the number of sources.\n",
        "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
        "----------------\n",
        "{summaries}\n",
        "\n",
        "You MUST answer in Korean:\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu83UZwtU0QJ"
      },
      "source": [
        "## **4) 검색 파이프라인 구현**\n",
        "\n",
        "---\n",
        "\n",
        "데이터를 가지고 쿼리 시스템을 만듭니다.\n",
        "\n",
        "### **쿼리 시스템**\n",
        "쿼리 시스템은 사용자가 입력한 질문(쿼리)과 사전에 저장된 데이터베이스(ChromaDB)의 정보를 비교하여 가장 관련성이 높은 결과를 반환하는 기능을 구현합니다. 이 과정은 크게 사용자 입력 처리, 유사성 검색, 결과 반환 세 단계로 나뉩니다.\n",
        "\n",
        "직접 쿼리를 입력하고 결과를 출력하는 시스템으로 구현하였습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vdr2Q2vYKcBL"
      },
      "outputs": [],
      "source": [
        "# 사용자 입력 기반 검색 시스템\n",
        "# 사용자가 질문을 입력하면 시스템이 관련 데이터를 검색하고 결과를 반환합니다.\n",
        "while True:\n",
        "    user_query = input(\"질문을 입력하세요: (종료하려면 '종료'를 입력하세요): \").strip()\n",
        "    if user_query.lower() == '종료':\n",
        "        print(\"검색 시스템을 종료합니다.\")\n",
        "        break\n",
        "    # 사용자가 질문을 받고 처리한다.\n",
        "\n",
        "    # 검색 결과 가져오기\n",
        "    # 사용자의 질문(user_query)과 관련된 문서를 ChromaDB에서 검색\n",
        "    results = retriever.get_relevant_documents(user_query)\n",
        "\n",
        "    if results:\n",
        "      print(\"\\n[검색 결과]\")\n",
        "      # 검색된 결과 중 가장 관련성이 높은 첫 번째 결과만 출력\n",
        "    # 가장 첫 번째 결과만 출력\n",
        "      result = results[0]  # 첫 번째 결과 가져오기\n",
        "      print(f\"1. {result.page_content}\")\n",
        "      print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    else:\n",
        "      print(\"\\n관련 문서를 찾을 수 없습니다.\\n\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
